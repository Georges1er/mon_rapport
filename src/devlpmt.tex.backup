%% Copyright (C) 2008 Johan Oudinet <oudinet@lri.fr>
%%  
%% Permission is granted to make and distribute verbatim copies of
%% this manual provided the copyright notice and this permission notice
%% are preserved on all copies.
%%  
%% Permission is granted to process this file through TeX and print the
%% results, provided the printed document carries copying permission
%% notice identical to this one except for the removal of this paragraph
%% (this paragraph not being relevant to the printed manual).
%%  
%% Permission is granted to copy and distribute modified versions of this
%% manual under the conditions for verbatim copying, provided that the
%% entire resulting derived work is distributed under the terms of a 
%% permission notice identical to this one.
%%  
%% Permission is granted to copy and distribute translations of this manual
%% into another language, under the above conditions for modified versions,
%% except that this permission notice may be stated in a translation
%% approved by the Free Software Foundation
%%  
\chapter{Etat de l'art}
\newline{}
\section{Préliminaires}    
\label{sec:prelimin} 
\subsection{Le cloud computing} 
L’expansion d’Internet a permis l’émergence du   cloud computing. 
La définition la plus répandue et acceptée est celle du \cite{NIST}. Le NIST définit  le  Cloud computing, comme un modèle Informatique qui permet un accès facile et à la demande par le réseau à un ensemble partagé de ressources informatiques configurables (serveurs, stockage, applications et services) qui peuvent être rapidement provisionnées et libérées par  un minimum d’efforts de gestion ou d’interaction avec le fournisseur du service.
D’un point de vue technique,  le cloud est la réunion  de plusieurs concepts informatiques dont les  principaux sont le Grid computing \cite{Grid} et la virtualisation.  Le Grid computing permet l’agrégation des ressources distribuées. La virtualisation quant à elle assure les  trois propriétés suivantes :
\begin{itemize} 
 \item  \textbf{Mutualisation des ressources}: la virtualisation permet d’affecter les ressources d’une même machine à plusieurs applications;
 \item  \textbf{ Abstraction de la localisation}: L’utilisateur a accès à une machine virtuelle complète qui  se trouve  quelque part  sur un serveur, comme si elle lui était locale;
 \item  \textbf{Elasticité} : Il est possible d’allouer des ressources supplémentaires à une application en fonction des besoins.
\end{itemize}\newline{}

 On distingue en outre, plusieurs types de cloud: 

 \begin{itemize} 
 \item  \textbf{Cloud privé}: L’infrastructure Cloud est utilisée par une seule organisation. Elle peut être gérée par l’organisation ou par une tierce partie (Ex: OpenStack \cite{openstack});
 \item  \textbf{ Cloud public}: L’infrastructure Cloud est partagée par plusieurs organisations pour les besoins d’une communauté qui souhaite mettre en commun des moyens (sécurité, conformité, etc..);
 \item  \textbf{Cloud hybride} : L’infrastructure Cloud est composée d’un ou plusieurs modèles  ci-dessus qui restent des entités séparées. 
\end{itemize}\newline{}


Structurellement, trois modèles de services peuvent être offerts sur le Cloud:              
   
\begin{itemize} 
 \item  \textbf{Software-as-a-Service (SaaS)}: Ce modèle de service est caractérisé par l’utilisation d’une application partagée qui fonctionne sur une infrastructure Cloud. L’utilisateur accède  à l’application par le réseau au travers de divers types de terminaux (souvent via un navigateur Web). 
 \item  \textbf{ Platform-as-a-Service (PaaS)}: l’utilisateur a la possibilité de créer et de déployer sur une infrastructure Cloud PaaS ses propres applications en utilisant les langages et les outils du fournisseur. L’utilisateur ne gère pas ou ne contrôle pas l’infrastructure Cloud sous-jacente (réseaux, serveurs, stockage) mais contrôle l’application déployée et sa configuration.
 \item  \textbf{Infrastructure-as-a-Service (IaaS)} :L’utilisateur loue des moyens de calcul et de stockage, des capacités réseau et d’autres ressources indispensables (partage de charge, pare-feu, cache). L’utilisateur a la possibilité de déployer n’importe quel type de logiciel incluant les systèmes d’exploitation.  
\end{itemize} \newline{}
\newline{}
\par 
L’un des concepts majeurs associés au cloud est la multi-tenancy ou la possibilité d'avoir des infrastructures multi-locataires.  La multi-tenancy permet à des entités d’exécuter simultanément  des instances d’une même application, d’un même réseau ou d’une même plateforme.
Nous nous intéressons maintenant à l’architecture  des caches des processeurs qui constituent le principal vecteur d’attaque dans notre étude. 

\subsection{Architecture et fonctionnement des caches}   
L’avènement des nouvelles générations de processeur telles que les multi-cœurs imposent des architectures plus performantes. C’est ce qui a favorisé le concept de \textbf{cache}. Les caches ou mémoires cache sont des mémoires très rapides mais de faible capacité de stockage servant à  stocker des données temporaires. Les caches ont été instaurés dans les architectures matérielles  des processeurs afin de limiter l’impact des temps d’accès à la mémoire depuis le processeur vers la mémoire centrale et vice-versa. Les caches fonctionnent sur deux principes fondamentaux : \textbf{la localité spatiale} et \textbf{ localité temporelle}. La localité spatiale est le fait que le processeur a tendance à accéder aux données proches des données accédées précédemment. La localité temporelle consiste au fait que le processeur a également tendance à accéder à une donnée accédée récemment. Le cache est divisé en blocs de même taille appelés \textbf{lignes de caches} contenant des blocs de  lignes de mot de la mémoire centrale appelées\textbf{pages}. La correspondance entre les lignes de caches et les pages se fait de différentes manières. On distingue alors 3 types de caches: 
\begin{enumerate}
 \item  \textbf{Les caches à  correspondance directe}: Chaque page de la mémoire correspond à une unique ligne dans le cache. Cette méthode à l’avantage de permettre un accès rapide à la ligne de cache  car on sait directement où elle se trouve. Cependant cette méthode s’avère peu efficace en pratique car on a souvent les mêmes données accédées tandis que les autres restent inutilisées.
 \item  \textbf{Les caches associatifs}: Dans ce type de cache, chaque page peut être chargée dans n’importe quelle ligne de cache. L’avantage ici c’est qu’on a un accès rapide au cache. Le principal goulot d’étranglement est la recherche d’une donnée préalablement dans le cache ce qui peut nécessiter de parcourir toutes les lignes.
 \item  \textbf{Cache way-associatif}: c’est un compromis entre les deux types précédents de cache. Dans ce cas, le cache est subdivisé en k blocs de taille égale appelé \textbf{sets}, chaque bloc comprenant un certain nombre \textit{w} (\textbf{way}) de lignes de cache. Chaque  page appartient correspond à un unique set, mais l’accès dans le set  se fait de manière aléatoire. C’est ce type de cache qui est le plus utilisé dans les architectures actuelles.
\end{enumerate}
\par

Ces architectures proposent une hiérarchie de cache organisée en plusieurs niveaux. Un niveau L1 plus près de la mémoire avec un accès rapide et une  taille moins importante généralement scindé en deux parties : une partie données (D), et une partie  instructions (I). On a en outre le niveau L2 qui est un peu moins rapide que  le niveau L1 mais plus grand en espace. Finalement, certains processeurs disposent d’un troisième niveau L3 de cache plus grand en espace mais le moins rapide.  Pour chercher les données, on commence   d’abord par le cache L1 ; dans ce cas on a un cache hit si la donnée est trouvée sinon on a un cache miss et on continue la recherche dans le cache L2 voire le cache  L3 au besoin.

\section{Attaques par canaux auxiliaires} 
\subsection{Définition et classification}
     
Les prouesses de la cryptographie moderne ont permis la conception d’algorithmes mathématiquement  prouvés robustes et sûrs (\cite{Kocher}, \cite{Rsapaper}). Ces algorithmes suffisent  donc théoriquement  pour assurer  la confidentialité, l’intégrité, l’authenticité des données sensibles d’une  personne ou d’une entité. Bien que ces algorithmes soient sûrs, leurs implémentations logicielles ou matérielles peuvent être sujettes à des attaques dites attaques par \textbf{canaux cachés}. Une attaque par canaux cachés  utilise des moyens de communication qui normalement  ne sont pas prévus  pour laisser fuir les informations \cite{Covert}(ex. écrire et vérifier si  un fichier verrouillé pour convenir un bit « 1 » ou « 0 »). On a un processus \textit{émetteur} et un autre processus \textit{récepteur} . L’émetteur pourrait bien être  un programme malveilant préalablement installé sur le système de la victime  par l’attaquant après avoir compromis ce système et le récepteur un processus non privilégié. \newline{}

\newline{}
\par

Une attaque par \textbf{canal auxiliaire} est un type particulier d’attaque par canaux cachés. Dans ce type d’attaque, Il n’y a pas de compromission des mécanismes de sécurité. En effet, ces attaques se font d’abord par l’analyse fine de  la consommation électrique, de l’émanation électromagnétique  ou bien du temps pendant  l’exécution  d’un  système cryptographique. L’exploitation des résultats de la phase d'analyse rend l’attaquant  capable   de  recouvrir des bits de clés de chiffrement de certains algorithmes. 
Il existe deux grandes familles d’attaques par canaux auxiliaires selon \cite{sidechannelattack}: \textbf{les attaques internes} et\textbf{les attaques externes}. Dans une attaque interne, l’espion contrôle soit  un processus ou une application dans un environnement partagé tel que  le cloud. Ce type d’attaques est basé sur  l’analyse de l’utilisation d’une ressource matérielle partagée comme le cache des processeurs ou les disques durs. Par contre dans une attaque externe, l’attaquant  réussit  au préalable à posséder physiquement un système informatique avant de réaliser l’attaque. \newline{}

\newline{}
\par


On distingue en outre plusieurs manières d’effectuer les attaques dont certaines sont communes aux deux familles d’attaques mentionnées plus haut.Il s’agit :
\begin{enumerate}
 \item  Des attaques basées sur \textbf{les accès aux ressources}: L’attaquant inspecte  l’état de la ressource partagée lorsque la victime est en fonctionnement et effectue ces analyses à la suite. Ces attaques sont le plus souvent réalisées sur  \textbf{les caches} ou \textbf{les prédicteurs de branche}. Ces attaques sont les plus représentatives dans le cloud puisque cette technologie se base sur le partage de ressources. 
 \item Des attaques basées sur \textbf{ le temps d’exécution}: Dans ce cas de figure, l’attaquant s’appuie sur le temps d’exécution pour compromettre le système. En effet, il exécute plusieurs fois le programme en  fournissant des données différentes en entrée  et à chaque exécution enregistre le temps mis. Il s’ensuit une analyse de ces temps pour inférer les clés de sécurité.
 \item Des attaques basées sur \textbf{ les traces}: Ce type d’attaque se base sur l’évaluation de  la consommation énergétique des systèmes cryptographiques. Il s’agit en fait de mesurer le courant électrique consommé par les circuits électroniques composant ces systèmes lorsqu’ils exécutent des programmes cryptographiques.  Une trace est alors un ensemble de mesures de consommation effectuées pendant le déroulement d’une opération. L’analyse des courbes obtenues et des niveaux de courant enregistrés sert à la conjecture des bits  des clés. Ces attaques sont le plus souvent effectuées sur des composants embarqués comme les cartes à puces. Par ailleurs, on trouve deux  sous-classes dans cette famille \cite{Kocher}:
  \begin{itemize}
   \item  \textbf{La SPA (Simple Power Analysis)}: Dans cette sous-classe, les données  recueillies après la phase d’analyse sont directement  exploitées et interprétées.
   \item  \textbf{La DPA (Differential Power Analysis)}: Ici par contre on effectue l’analyse différentielle de la consommation. En fait, on combine les résultats de la phase d’analyse avec  des méthodes statistiques pour l’extraction des clés.
  \end{itemize}
Ces deux sous-classes d’attaques sont facilement automatisables et ne nécessite pas la connaissance de l’architecture de la plateforme cible.
\end{enumerate}\newline{}

\newline{}

Dans le cloud la ressource matérielle la plus utilisée comme vecteur d’attaques par canaux auxiliaires  est le cache. Ceci étant, notre présente étude se limitera aux attaques basées \textbf{les accès aux caches}
\subsection{Attaques par canaux auxiliaires dans le cloud}
\subsubsection{Attaques visant les caches L1 et L2}
Les attaques par canaux auxiliaires existaient bien avant l’apparition du cloud computing. Les attaques dans le cloud sont rendues possibles grâce au concept de multi-tenancy. La première étude qui a révélé la vulnérabilité  des plateformes de cloud computing est \cite{Ris2009}.L’attaque  a été menée sur  la plateforme de cloud public Amazon Web Services \cite{amazon} avec l’hyperviseur Xen \cite{xen}. Il faut noter qu’un hyperviseur est un logiciel système qui assure le lancement, la gestion et l’approvisionnement des machines virtuelles dans une plateforme cloud. Dans le cas de l’hyperviseur XEN, on distingue une machine virtuelle particulière et  privilégiée dénommée Dom0 qui agit comme orchestrateur des autres machines virtuelles et assure les fonctions de gestion. L’attaque s’est faite selon deux étapes distinctes:
\begin{enumerate} 
\item la première étape  a permis à  l' attaquant de faire une cartographie des adress internet et lancer sa machine virtuelle(VM) sur une même plateforme physique (CPU, cœur)  que la VM cible, ce qui est  connu sous le terme de \textbf{co-résidence}. Deux machines virtuelles sont considérées co-résidentes si l’une des trois conditions suivantes est vérifiée:
\begin{itemize}
 \item Elles ont des adresses internes proches;
 \item On a des latences réseau faibles entre les machines;
 \item Leurs adresses correspondent en partie à l’adresse  IP de Dom0;
\end{itemize}
\item La seconde étape consiste à l’exploitation de la co-résidence. L’attaquant utilise pour ce faire, la méthode du \textbf{PRIME TRIGGER AND PROBE}  qui est une variante de la méthode  du \textbf{ PRIME AND PROBE}.
\end{enumerate}

Le fonctionnement de la méthode du  \textbf{ PRIME AND PROBE} \cite{Osvik} est le suivant:
\begin{enumerate}
 \item L’attaquant remplit une ou plusieurs lignes du cache avec des données aléatoires;
 \item Puis il laisse la main à la victime pour qu’elle puisse s’exécuter;
 \item L’attaquant charge alors ces mêmes  données dans ces  mêmes lignes  de cache et mesure le temps mis pour le chargement.	
\end{enumerate}

Le temps de chargement est parfaitement corrélé à l’accès de la victime au cache. Un temps de chargement d’une ligne de cache plus grand indique  que cette ligne de cache a été accédée par la victime et ses données ont été éjectées du cache. Par contre, une faible durée montre que la partie du cache L2 concernée est restée intacte. Ces mesures  ont permis  de mesurer le trafic d'un serveur Web et de détermier le lien entre les pics de  charge du cache  et les frappes des touches du clavier. En conclusion, il faut noter que  ces attaques ne sont pas assez robustes, car elles génèrent assez de faux-positifs et on ne peut qu’obtenir certaines parties des clés de chiffrement. Néanmoins cette étude, a ouvert  ce domaine de recherche et  a servi de tremplin aux futures attaques par canaux auxiliaires. \newline{}

\newline{}
\par 

Ainsi, une nouvelle attaque  a été montée\cite{Zhang2012}. L'attaque s'est déroulée des systèmes \textbf{ SMP (Symetric multiprocessing)}avec l’hyperviseur Xen. Le SMP est un mode de fonctionnement particulier où tous les processeurs exécutent en parallèle le même calcul.L’hypothèse  de base est  que l’attaquant est incapable d’exploiter des vulnérabilités logicielles qui lui permettent de prendre contrôle de l’infrastructure physique et n’a aucune  connaissance du logiciel cryptographique qu’exécute la victime. L’attaque  vise à recouvrir les clés de l’algorithme de chiffrement Elgamal [28]. L'attaquant a d'abord obtenu la co-résidence avec la victime et par la suite il a mesurée l'activité du cache  L1 grâce à la méthode du \textbf{PRIME AND PROBE}.  
\par
Il faut noter que pour qu’une attaque par canaux auxiliaires soit réalisable, il faudrait que l’attaquant ait la possibilité de préempter régulièrement la victime. Lors de la mise en œuvre de la phase de mesure, l'attaquant a donc  été confronté à des difficultés  puisque le \textbf{ multithreading} n’était pas activé. Le multithreading est la capacité de lancer plusieurs threads dans une unité de calcul (cœur par exemple) d’un processeur. Le multithreading  temporel se fait quand les threads s’exécutent tour à tour et le multithreading simultané  quand les threads s’exécutent simultanément. L'attaquant a réussi à contourner cet obstacle  en se basant sur le comportement de l’hyperviseur Xen consistant à donner la priorité d’exécution aux  processeurs virtuels (Virtual CPU)  recevant des interruptions.L'attaquant peut régulièrement préempter la victime  en lançant des interruptions interprocessus.  L'étape  finale est donc la classification  des mesures de l'activité du cache et la détection des faus positifs grâce aux techniques de classification empruntées utilisés dans les techniques d’apprentissage automatique (Machine Learning). Grâce à leur technique, les auteurs ont cassé l’algorithme de chiffrement Elgamal. Cette attaque est la première attaque par canaux auxiliaires dans le cloud la plus robuste avec une très fine granularité. \newline{}

\newline{}
\par 

Une autre méthode d'attaque est la technique  de l'\textbf{EVICT + TIME} \cite{Osvik} qui s'effectue également en trois étapes:
\begin{enumerate}
 \item D'abord, le programme de la victime est lancé et son temps d'exécution est mesuré;
 \item ensuite, l'attaquant évince un set spécifique du cache;
 \item finalement, il mesure de nouveau le temps d'exécution de la victime.
\end{enumerate}
Si le temps d'exécution croit, la victime a éventuellement accédé au cache.
Toutes  ces attaques  que nous avons présentées ne se basent que sur la mesure de l’activité des caches  L1 et L2. Nous verrons donc dans ce qui suit des attaques qui exploitent les caches L3.
\subsubsection{Attaques visant les caches L3}

Les caches L3 étant les caches les moins rapides d’accès,  très peu d’attaques utilisant ce cache comme vecteur d’attaque aboutissent. Une attaque ayant eu du succès est celle de Yuval et al. \cite{Yuval}. Les auteurs ont montré la possibilité de monter une attaque par canaux auxiliaires dans le cloud au travers du cache L3.  Leur attaque tire parti de la politique  \textbf{ déduplication de mémoire} qui est une technique de partage des pages dans les architectures \textbf{ Intel X86} qui assure la performance en  évitant  la réplication de copies de même contenu et la réduction des traces de la mémoire. 
Elle introduit  par ailleurs une nouvelle méthode d’attaque, le  \textbf{ FLUSH AND RELOAD} qui est une variante de la méthode PRIME AND PROBE.  Elle nécessite que la victime et l’attaquant partagent la hiérarchie de cache, et les pages de la mémoire et doivent être co-localisées. Le fonctionnement de  cette méthode se fait en trois étapes :
\begin{enumerate}
 \item On évince la partie de la mémoire concernée du cache. Dans les architectures x86, l’instruction \textbf{cflush} permet de réaliser cette opération;
 \item l’attaquant attends ensuite afin que la victime puisse accéder à la mémoire;
 \item l’attaquant recharge la donnée à partir de la mémoire  en mesurant le temps de chargement.
\end{enumerate}


L’approche utilisée pour l’attaque est de tracer l’exécution du programme de la victime. L’attaquant applique la technique du \textbf{ FLUSH AND RELOAD} à un espace mémoire à l’intérieur du segment de code de la victime. Pour ce faire, les auteurs ont divisés le temps en quantum de  2048 cycles. Dans chaque quantum  de temps, l’attaquant sonde  une ligne de mémoire correspondant à soit une opération d’élévation au carré, de multiplication ou de réduction conformément à l’algorithme RSA figure 3. Les séquences d’exécution dans chaque quantum le bit utilisé. Ainsi la séquence multiplication- réduction indique un bit positif tandis que la séquence carre-réduction un bit nul. Cette attaque bien que pouvant trouver jusqu’à 90\% des bits,est limitée pace qu’on ne peut pas déterminer la position des bits quand des erreurs se présentent. Plusieurs tentatives peuvent permettre de trouver la clé puisque plusieurs tests ont une faible probabilité d’avoir des erreurs à la même position. Cependant pour que l’attaque marche,  il faudrait que la victime et l’espion s’exécutent sur le même processeur physique. L’attaque peut être entravée par les bruits dus aux activités d’autres processus.
Comme nous l’avons signifié plus haut, cette attaque n’est possible qu’avec l’hypothèse que la déduplication de mémoire est activée. Il faut noter qu'en dépit des avantages de la déduplication, les principaux  fournisseurs de cloud actuelsl’ont formellement  désactivée puisqu’elle induit   également des failles de sécurité. \newline{}


Pour montrer que les attaques par canaux auxiliaires utilisant le cache L3 sont toujours possibles sans le mécanisme de déduplication, une nouvelle approche basée sur la méthode du PRIME AND PROBE a été proposé \cite{Fangfei}. Il faut noter qu’une attaque par  la méthode du prime and probe est difficilement réalisable avec les caches L3. Selon les auteurs, les principales raisons à l’origine de cette difficulté sont  la grande taille du cache et le fait que  l’attaquant et la victime ne sont pas sur le même cœur. L’attaquant a une faible visibilité de l’activité de la victime. Pour finir il est également difficile de savoir les parties du cache L3 relatives à des informations sensibles. 
\par Des moyens de contournement ont été investigués.Pour la faible visibilité de l’activité de la victime, on introduit l’inclusion des caches. Le principe de ce mécanisme  est que toute donnée introduite ou évincée dans le cache L1 est également copiée ou évincée  dans les autres  niveaux de caches. Ainsi l’attaquant  peut remplacer la donnée dans la hiérarchie de cache sans accéder au cache de plus haut niveau. Pour  le problème de la taille  du cache L1, il s’agira d’effectuer uniquement la méthode du PRIME AND PROBE sur les blocs correspondant aux parties sensibles tout en ayant au préalable déterminé ces blocs. Enfin pour déterminer ces parties sensibles,  l’idée est de parcourir tout le cache L3 mais en parcourant un seul set à la fois et de détecter les motifs d’accès à ce cache relatifs aux données sensibles. Fort de ces mesures, les auteurs ont monté une attaque contre l’algorithme de chiffrement Elgamal. Elle a permis de recouvrir la totalité des clés de chiffrement avec un taux de faux positifs relativement faible. 
            
\subsubsection{Attaques visant les plateformes PaaS}
Toutes les attaques  précédentes n’étaient effectuées que sur des plateformes cloud Iaas.  Zhang et al. ont montré dans \cite{ZhangPaas} que les attaques par canaux auxiliaires étaient également possibles sur des plateformes Paas. C’est la première attaque de ce genre. L’attaque qu’ils proposent est basée sur la méthode du FLUSH AND RELOAD vue précédemment. 
Le choix de cette méthode aux dépens de  la méthode de PRIME AND PROBE est que le FLUSH AND RELOAD  génère moins de bruit car l’attaquant est capable d’identifier clairement quand la victime a accédé à  la donnée du bloc de mémoire en cours d’évaluation. 

\par Cette attaque se fait avec l’hypothèse que l’attaquant et la victime sont des utilisateurs d’une certaine plateforme Paas et  l’attaquant  tente de faire  exécuter ses instances à l’intérieur du même conteneur que la victime pour extirper les clés de chiffrement de la victime. Un conteneur est un environnement système minimal. Pour monter leur attaque, un nouveau outil permettant à l’attaquant de tracer le chemin d’exécution de la victime dans  les exécutables  partagés a été défini.  A partir du graphe de flot de contrôle (CFG) de l’exécutable partagé avec la victime, partage rendu possible grâce à la multi-tenancy, l’attaquant construit un automate  qui  permet d’inférer les différents chemins possibles que pourrait emprunter la victime lors de son exécution. La première étape de toute attaque par canaux auxiliaires dans le cloud consiste à atteindre la co-résidence. Sur les environnements Paas, l’état de l’art actuel ne fournit aucune méthode de détection. Les auteurs ont donc proposé une approche de détection de la co-résidence en deux sous-étapes différentes. Dans la première, il s’agira de lancer plusieurs instances jusqu’à ce qu’elles aboutissent à la co-résidence. 
\par A la suite, la seconde sous-étape se fait en utilisant la méthode du FLUSH AND RELOAD. L’attaquant lance des requêtes HTTP aux instances de la victime et monitore un chemin d’exécution particulier  découlant de l’automate construit. Si  l’automate transite vers un état acceptant de l’adversaire, l’adversaire connaît donc le chemin critique de la victime. 

Avec cette nouvelle méthode, l'attaquant peut réinitialiser le mot de passe d’une victime. Cette étude a donc ouvert la recherche sur la vulnérabilité des plateformes Paas aux attaques par canaux auxiliaires.
Les attaques par canaux auxiliaires dans le cloud  comme nous l’avons vu dans cette section, sont  indiscutablement  devenues des menaces réelles pour les fournisseurs de cloud. A cet effet, plusieurs  moyens de lutte ont été proposés par des chercheurs  industriels et des chercheurs académiques  pour contrer ces attaques. Nous les verrons en détail dans la section suivante.

\section{Contremesures} 

Les attaques par canaux auxiliaires dans leur mise en œuvre, nécessitent la combinaison de plusieurs conditions : \textbf{ un vecteur d’attaque, une source d’attaque, et une cible d’attaque}. Empêcher un de ces trois composants peut suffire à rendre l’attaque inexploitable. De ce fait, les contremesures proposées pour se prémunir contre  ces attaques  de par leur diversité et leur spécificité peuvent  être regroupées en plusieurs catégories. On prendra  soin de préciser au niveau de quelle couche (Système, VM, Hyperviseur, matérielle) et qui peut mettre en œuvre ces contremesures (Utilisateur, fournisseur de cloud).

    
  
      



    






%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "rapportM2R"
%%% End: 
